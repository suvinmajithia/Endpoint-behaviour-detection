{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94e978b-0004-417a-8b10-6e722e07fee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Evtx imported: /opt/anaconda3/lib/python3.13/site-packages/Evtx/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-evtx==0.8.1 lxml pandas -q\n",
    "import importlib\n",
    "import Evtx  # Force load\n",
    "print(\"✅ Evtx imported:\", Evtx.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be747200-f369-4e7e-8eda-e5bb25f8ecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping evtx as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mFound existing installation: python-evtx 0.8.1\n",
      "Uninstalling python-evtx-0.8.1:\n",
      "  Successfully uninstalled python-evtx-0.8.1\n",
      "Collecting evtx==0.8.9\n",
      "  Using cached evtx-0.8.9-cp37-abi3-macosx_11_0_arm64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.13/site-packages (1.6.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.13/site-packages (1.15.3)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.13/site-packages (3.10.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.13/site-packages (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached evtx-0.8.9-cp37-abi3-macosx_11_0_arm64.whl (884 kB)\n",
      "Installing collected packages: evtx\n",
      "Successfully installed evtx-0.8.9\n"
     ]
    }
   ],
   "source": [
    "# Install packages\n",
    "!pip uninstall evtx python-evtx -y\n",
    "!pip install evtx==0.8.9 pandas scikit-learn scipy seaborn matplotlib pyyaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908aeb85-3230-4c2c-972f-c43f8a47227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MITRE Threats:\n",
      "|    | MITRE_ID   | Technique          | EVTX_File       | Sigma_Target    |\n",
      "|---:|:-----------|:-------------------|:----------------|:----------------|\n",
      "|  0 | T1218.001  | rundll32 LOLBin    | rundll32.evtx   | rundll32.*http  |\n",
      "|  1 | T1059.001  | PowerShell Encoded | powershell.evtx | powershell -enc |\n"
     ]
    }
   ],
   "source": [
    "# MITRE Threads Table\n",
    "import pandas as pd\n",
    "import json\n",
    "from evtx import PyEvtxParser  # ✅ CORRECT import\n",
    "\n",
    "# MITRE table\n",
    "threats = pd.DataFrame({\n",
    "    'MITRE_ID': ['T1218.001', 'T1059.001'], \n",
    "    'Technique': ['rundll32 LOLBin', 'PowerShell Encoded'],\n",
    "    'EVTX_File': ['rundll32.evtx', 'powershell.evtx'],\n",
    "    'Sigma_Target': ['rundll32.*http', 'powershell -enc']\n",
    "})\n",
    "print(\"MITRE Threats:\")\n",
    "print(threats.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8adca0f-5196-4e67-b753-acb372e38203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-evtx\n",
      "  Using cached python_evtx-0.8.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.13/site-packages (6.0.2)\n",
      "Requirement already satisfied: hexdump>=3.3 in /opt/anaconda3/lib/python3.13/site-packages (from python-evtx) (3.3)\n",
      "Using cached python_evtx-0.8.1-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: python-evtx\n",
      "Successfully installed python-evtx-0.8.1\n",
      "✅ Parsed 0 events!\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "!pip install python-evtx lxml\n",
    "\n",
    "from Evtx.Evtx import Evtx\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_evtx_safe(file_path):\n",
    "    events = []\n",
    "    with Evtx(file_path) as log:\n",
    "        for record in log.records():\n",
    "            try:\n",
    "                xml = ET.fromstring(record.xml())\n",
    "                events.append({\n",
    "                    'EventID': xml.find('.//EventID').text,\n",
    "                    'TimeCreated': xml.find('.//TimeCreated').text\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "            if len(events) >= 10: break\n",
    "    return events\n",
    "\n",
    "logs = parse_evtx_safe('rundll32.evtx')\n",
    "print(f\"✅ Parsed {len(logs)} events!\")\n",
    "print(pd.DataFrame(logs).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e701af3a-c55e-40f1-9803-830acb31e96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded rundll32.evtx (T1218.001)\n",
      "Extracted 0 command lines:\n",
      "| CommandLine   |\n",
      "|---------------|\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Download T1218.001 sample\n",
    "url = \"https://github.com/sbousseaden/EVTX-ATTACK-SAMPLES/raw/master/T1218_001/System/S-0001_rundll32_http.evtx\"\n",
    "response = requests.get(url)\n",
    "with open(\"rundll32.evtx\", \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "print(\"Downloaded rundll32.evtx (T1218.001)\")\n",
    "\n",
    "# Extract process creation command lines (Event ID 4688)\n",
    "cmdlines = []\n",
    "with Evtx(\"rundll32.evtx\") as log:\n",
    "    for record in log.records():\n",
    "        try:\n",
    "            xml = ET.fromstring(record.xml())\n",
    "            cmd_elem = xml.find('.//Data[@Name=\"NewProcessCommandLine\"]')\n",
    "            if cmd_elem is not None:\n",
    "                cmdlines.append(cmd_elem.text)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "df_cmd = pd.DataFrame({'CommandLine': cmdlines})\n",
    "print(f\"Extracted {len(df_cmd)} command lines:\")\n",
    "print(df_cmd.head().to_markdown())\n",
    "df_cmd.to_csv('cmdlines.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df5a58d-d7e1-41ef-b83d-a735dbec07b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Vectorize command lines\u001b[39;00m\n\u001b[1;32m      5\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(df_cmd[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCommandLine\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train anomaly detector\u001b[39;00m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m IsolationForest(contamination\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:2104\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2098\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2099\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2100\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2101\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2102\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2103\u001b[0m )\n\u001b[0;32m-> 2104\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_transform(raw_documents)\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2106\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2107\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:1376\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1368\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1369\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1370\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1371\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1372\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1373\u001b[0m             )\n\u001b[1;32m   1374\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1376\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_count_vocab(raw_documents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_vocabulary_)\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1379\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:1282\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[0;32m-> 1282\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1283\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1284\u001b[0m         )\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Vectorize command lines\n",
    "vectorizer = TfidfVectorizer(max_features=50, stop_words='english')\n",
    "X = vectorizer.fit_transform(df_cmd['CommandLine'].fillna(''))\n",
    "\n",
    "# Train anomaly detector\n",
    "model = IsolationForest(contamination=0.3, random_state=42)\n",
    "anomaly_scores = model.fit_predict(X)\n",
    "\n",
    "# Results\n",
    "df_results = pd.DataFrame({\n",
    "    'CommandLine': df_cmd['CommandLine'],\n",
    "    'AnomalyScore': anomaly_scores\n",
    "})\n",
    "print(\"Anomalous command lines (score = -1):\")\n",
    "print(df_results[df_results['AnomalyScore'] == -1].to_markdown())\n",
    "df_results.to_csv('anomalies.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de2393b-ee2e-499e-9f0c-347676dc9b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
